{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Bank Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use logistic regression and neural network to solve a bank fraud detection case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, model_selection, linear_model, metrics, tree, svm\n",
    "from sklearn.metrics import classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data:**\n",
    "There are 23 features for each user, which are discribed below\n",
    "\n",
    "**id**: A unique Id field which represents a customer\n",
    "\n",
    "**X1**: Credit line\n",
    "\n",
    "**X2**: Gender (1 = male; 2 = female).\n",
    "\n",
    "**X3**: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "\n",
    "**X4**: Marital status (1 = married; 2 = single; 3 = others).\n",
    "\n",
    "**X5**: Age (year).\n",
    "\n",
    "**X6 - X11**: History of past payment. \n",
    "\n",
    "**X6** = September, 2015;\n",
    "\n",
    "**X7** = August, 2015;\n",
    "\n",
    "**...**\n",
    "\n",
    "**X11** =April, 2015; where -1 = pay one month ahead; -2 = pay two month ahead; 0 = pay on time; Positive means the payment delayed months, 1 = delay 1 month, 2 = delay 2 months, etc.\n",
    "\n",
    "**X12- X17**: Amount in bill statement.\n",
    "\n",
    "**X12** = amount of bill statement September, 2015\n",
    "\n",
    "**X13** = amount of bill statement August, 2015\n",
    "\n",
    "**...**\n",
    "\n",
    "**X17** = amount of bill statement April, 2015. \n",
    "\n",
    "**X18-X23**: Amount of previous payment\n",
    "\n",
    "**X18** = amount paid in September, 2015; \n",
    "\n",
    "**X19** = amount paid in August, 2015; \n",
    "\n",
    "**...**\n",
    "\n",
    "**X23** = amount paid in April, 2015.\n",
    "\n",
    "**Y**: Whether the customer is creditable (1) or not (0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>133207</td>\n",
       "      <td>136159</td>\n",
       "      <td>138741</td>\n",
       "      <td>6500</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5100</td>\n",
       "      <td>5000</td>\n",
       "      <td>5400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>130814</td>\n",
       "      <td>130758</td>\n",
       "      <td>123468</td>\n",
       "      <td>7500</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>4179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>350000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>119947</td>\n",
       "      <td>117328</td>\n",
       "      <td>118400</td>\n",
       "      <td>6000</td>\n",
       "      <td>5900</td>\n",
       "      <td>5800</td>\n",
       "      <td>4100</td>\n",
       "      <td>4500</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>240000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>12700</td>\n",
       "      <td>12500</td>\n",
       "      <td>26225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12700</td>\n",
       "      <td>0</td>\n",
       "      <td>13725</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>180000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>332</td>\n",
       "      <td>416</td>\n",
       "      <td>416</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>332</td>\n",
       "      <td>500</td>\n",
       "      <td>3500</td>\n",
       "      <td>832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      X1  X2  X3  X4  X5  X6  X7  X8  X9  ...     X15     X16     X17  \\\n",
       "0   1  200000   2   3   1  53   0   0   0   0  ...  133207  136159  138741   \n",
       "1   2  130000   2   3   2  39   0   0   0   2  ...  130814  130758  123468   \n",
       "2   3  350000   2   1   2  41   0   0   0   0  ...  119947  117328  118400   \n",
       "3   4  240000   2   2   1  43   1  -2  -2  -1  ...   12700   12500   26225   \n",
       "4   5  180000   1   2   2  28  -1  -1  -1  -1  ...     332     416     416   \n",
       "\n",
       "    X18    X19    X20   X21    X22   X23  Y  \n",
       "0  6500   5000   5000  5100   5000  5400  0  \n",
       "1  7500  10000      0  4500   4500  4179  0  \n",
       "2  6000   5900   5800  4100   4500  5000  0  \n",
       "3     0      0  12700     0  13725     0  0  \n",
       "4     0    416    332   500   3500   832  0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/Rockwell/Desktop/Bank-Fraud-Detection/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "train.isna().sum().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, no missing value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     int64\n",
       "X1     int64\n",
       "X2     int64\n",
       "X3     int64\n",
       "X4     int64\n",
       "X5     int64\n",
       "X6     int64\n",
       "X7     int64\n",
       "X8     int64\n",
       "X9     int64\n",
       "X10    int64\n",
       "X11    int64\n",
       "X12    int64\n",
       "X13    int64\n",
       "X14    int64\n",
       "X15    int64\n",
       "X16    int64\n",
       "X17    int64\n",
       "X18    int64\n",
       "X19    int64\n",
       "X20    int64\n",
       "X21    int64\n",
       "X22    int64\n",
       "X23    int64\n",
       "Y      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value types\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All in integers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     25000\n",
       "X1        79\n",
       "X2         2\n",
       "X3         7\n",
       "X4         4\n",
       "X5        56\n",
       "X6        11\n",
       "X7        11\n",
       "X8        11\n",
       "X9        11\n",
       "X10       10\n",
       "X11       10\n",
       "X12    19387\n",
       "X13    19025\n",
       "X14    18745\n",
       "X15    18423\n",
       "X16    17923\n",
       "X17    17577\n",
       "X18     7150\n",
       "X19     7062\n",
       "X20     6697\n",
       "X21     6217\n",
       "X22     6143\n",
       "X23     6169\n",
       "Y          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the categorical features\n",
    "train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that X2, X3, X4 are categorical features, i.e.,**\n",
    "\n",
    "**X2**: Gender (1 = male; 2 = female).\n",
    "\n",
    "**X3**: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "\n",
    "**X4**: Marital status (1 = married; 2 = single; 3 = others).\n",
    "\n",
    "**Also X1, X5, X6 - X11 are discrete features**\n",
    "\n",
    "**X1**: Credit line\n",
    "\n",
    "**X5**: Age (year).\n",
    "\n",
    "**X6 - X11**: History of past payment, where -1 = pay one month ahead; -2 = pay two month ahead; 0 = pay on time; Positive means the payment delayed months, 1 = delay 1 month, 2 = delay 2 months, etc.\n",
    "\n",
    "**Last other features are continuous features**\n",
    "\n",
    "**X12- X17**: Amount in bill statement.\n",
    "\n",
    "**X18-X23**: Amount of previous payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the correlations (it doesn't hurt to include all, since they are all ingeters)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(train.corr(), vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above figure, we can find X4 and X5 has negative correlation, pairs in X12-X17 have positive correlation. For accuracy we use values to decide. Let %97.5 be a threshold.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the upper triangle matrix of the correlation matrix\n",
    "df_corr = train.corr()\n",
    "df_corr_upper = pd.DataFrame(np.triu(df_corr, k=1)).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column indices with abs correlation larger than the threshold.\n",
    "dropcols_index = [j for j in range(len(df_corr_upper.columns)) if any(df_corr_upper.iloc[:,j] > 0.975)]\n",
    "dropcols_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, no strong correlation over the threshold, 97.5%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical feature encoding: one-hot encoding will be used in this analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X1</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>...</th>\n",
       "      <th>X3_1</th>\n",
       "      <th>X3_2</th>\n",
       "      <th>X3_3</th>\n",
       "      <th>X3_4</th>\n",
       "      <th>X3_5</th>\n",
       "      <th>X3_6</th>\n",
       "      <th>X4_0</th>\n",
       "      <th>X4_1</th>\n",
       "      <th>X4_2</th>\n",
       "      <th>X4_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200000</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126027</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130000</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>133825</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>350000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>240000</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>180000</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1832</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>24996</td>\n",
       "      <td>300000</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>24997</td>\n",
       "      <td>230000</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3745</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>24998</td>\n",
       "      <td>30000</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34048</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>24999</td>\n",
       "      <td>360000</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28291</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>25000</td>\n",
       "      <td>320000</td>\n",
       "      <td>41</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2197</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      X1  X5  X6  X7  X8  X9  X10  X11     X12  ...  X3_1  X3_2  \\\n",
       "0          1  200000  53   0   0   0   0    0    0  126027  ...     0     0   \n",
       "1          2  130000  39   0   0   0   2    0    0  133825  ...     0     0   \n",
       "2          3  350000  41   0   0   0   0    0    0  122017  ...     1     0   \n",
       "3          4  240000  43   1  -2  -2  -1    0    0       0  ...     0     1   \n",
       "4          5  180000  28  -1  -1  -1  -1   -1   -1    1832  ...     0     1   \n",
       "...      ...     ...  ..  ..  ..  ..  ..  ...  ...     ...  ...   ...   ...   \n",
       "24995  24996  300000  56   1  -2  -2  -2   -2   -2       0  ...     1     0   \n",
       "24996  24997  230000  36   0   0   0   2    0    0    3745  ...     0     1   \n",
       "24997  24998   30000  23   2   2   2   2    2    2   34048  ...     0     1   \n",
       "24998  24999  360000  36   0   0   0   0    0    0   28291  ...     1     0   \n",
       "24999  25000  320000  41  -2  -2  -2  -2   -2   -2    2197  ...     1     0   \n",
       "\n",
       "       X3_3  X3_4  X3_5  X3_6  X4_0  X4_1  X4_2  X4_3  \n",
       "0         1     0     0     0     0     1     0     0  \n",
       "1         1     0     0     0     0     0     1     0  \n",
       "2         0     0     0     0     0     0     1     0  \n",
       "3         0     0     0     0     0     1     0     0  \n",
       "4         0     0     0     0     0     0     1     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "24995     0     0     0     0     0     1     0     0  \n",
       "24996     0     0     0     0     0     1     0     0  \n",
       "24997     0     0     0     0     0     0     1     0  \n",
       "24998     0     0     0     0     0     1     0     0  \n",
       "24999     0     0     0     0     0     0     1     0  \n",
       "\n",
       "[25000 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding for X2 (gender), X3(education), X4(martial status)\n",
    "train_onehot = train.copy()\n",
    "train_onehot = pd.get_dummies(train_onehot, columns=['X2', 'X3', 'X4'], prefix=['X2', 'X3', 'X4'])\n",
    "train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the id column\n",
    "train_onehot.drop(labels='id', axis=1, inplace=True)\n",
    "# move label column to the last\n",
    "feature_cols = [col for col in train_onehot.columns if col != 'Y']\n",
    "train_onehot = train_onehot[feature_cols + ['Y']]\n",
    "# split data to train and validation\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_onehot.iloc[:,:-1], train_onehot['Y'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 33) (5000, 33) (20000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build logistic regression model\n",
    "lm_lr = linear_model.LogisticRegression(max_iter=1000, solver='lbfgs', tol=0.05, penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.05, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15529,  4469],\n",
       "       [    2,     0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for training set (col1-actual incredible, col2-actual credible)\n",
    "metrics.confusion_matrix(lm_lr.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3921, 1079],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for validation set (col1-actual incredible, col2-actual credible)\n",
    "metrics.confusion_matrix(lm_lr.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.78      1.00      0.87     15531\n",
      "    Credible       0.00      0.00      0.00      4469\n",
      "\n",
      "    accuracy                           0.78     20000\n",
      "   macro avg       0.39      0.50      0.44     20000\n",
      "weighted avg       0.60      0.78      0.68     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the training data\n",
    "print(classification_report(y_train, lm_lr.predict(X_train), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.78      1.00      0.88      3921\n",
      "    Credible       0.00      0.00      0.00      1079\n",
      "\n",
      "    accuracy                           0.78      5000\n",
      "   macro avg       0.39      0.50      0.44      5000\n",
      "weighted avg       0.61      0.78      0.69      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rockwell/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rockwell/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the validation data\n",
    "print(classification_report(y_valid, lm_lr.predict(X_valid), target_names=['Incredible', 'Credible']))\n",
    "# Store the report to dataframe\n",
    "report = classification_report(y_valid, lm_lr.predict(X_valid), target_names=['Incredible', 'Credible'], output_dict=True)\n",
    "df_report_lm_lr = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the confusion matrices and performance reports for both training and validation sets, we can see the logistic regression model has a high recall on incredible users, which is actually a good aspects for fraud detection.**\n",
    "\n",
    "**However, the precision on incredible users are just 78% and there are only a few customers are recogonized as credible in the training data and 0 user recogonized as credible in the validation data. This could lead to a problem of mistakenly regarding too many valuable and credible users as bad users. Thus the credit card company might lose a lot of business opportunities and revenue from it. Hence the logistic regression model is not ideal enough and could be improved.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we use the original values without one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and validation\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train.iloc[:,:-1], train['Y'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 24) (5000, 24) (20000,) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.05, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build logistic regression model\n",
    "lm_lr = linear_model.LogisticRegression(max_iter=1000, solver='lbfgs', tol=0.05, penalty='l2')\n",
    "lm_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15525,  4473],\n",
       "       [    0,     2]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for training set (col1-actual incredible, col2-actual credible)\n",
    "metrics.confusion_matrix(lm_lr.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3927, 1073],\n",
       "       [   0,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix for validation set (col1-actual incredible, col2-actual credible)\n",
    "metrics.confusion_matrix(lm_lr.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.78      1.00      0.87     15525\n",
      "    Credible       1.00      0.00      0.00      4475\n",
      "\n",
      "    accuracy                           0.78     20000\n",
      "   macro avg       0.89      0.50      0.44     20000\n",
      "weighted avg       0.83      0.78      0.68     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the training data\n",
    "print(classification_report(y_train, lm_lr.predict(X_train), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.79      1.00      0.88      3927\n",
      "    Credible       0.00      0.00      0.00      1073\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.39      0.50      0.44      5000\n",
      "weighted avg       0.62      0.79      0.69      5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rockwell/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Rockwell/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the validation data\n",
    "print(classification_report(y_valid, lm_lr.predict(X_valid), target_names=['Incredible', 'Credible']))\n",
    "# Store the report to dataframe\n",
    "report = classification_report(y_valid, lm_lr.predict(X_valid), target_names=['Incredible', 'Credible'], output_dict=True)\n",
    "df_report_lm_lr_no_onehot = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen that without one-hot encoding, the performance is almost the same.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we use decision tree, instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build decision tree model\n",
    "d_dtc = tree.DecisionTreeClassifier()\n",
    "d_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15525,     0],\n",
       "       [    0,  4475]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(d_dtc.predict(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3186,  622],\n",
       "       [ 741,  451]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(d_dtc.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       1.00      1.00      1.00     15525\n",
      "    Credible       1.00      1.00      1.00      4475\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the training data\n",
    "print(classification_report(y_train, d_dtc.predict(X_train), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.84      0.81      0.82      3927\n",
      "    Credible       0.38      0.42      0.40      1073\n",
      "\n",
      "    accuracy                           0.73      5000\n",
      "   macro avg       0.61      0.62      0.61      5000\n",
      "weighted avg       0.74      0.73      0.73      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the validation data\n",
    "print(classification_report(y_valid, d_dtc.predict(X_valid), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be seen from the above results, decision tree model generate a better performance than logistic regression, F1-score for weighted avg is 0.73 > 0.69**\n",
    "\n",
    "**Even though the recall for credible users increase a lot, the recall for the incredible users descrease from 1 to 0.82. Also the trained model performs perfect on training set but not very good on validation set, which means we overfit the model, so some parameters should be tuned**\n",
    "\n",
    "**First to simplify the tree structure, limit the maximum layers to a lower number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build decision tree model\n",
    "d_dtc = tree.DecisionTreeClassifier(max_depth=5)\n",
    "d_dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.84      0.95      0.89     15525\n",
      "    Credible       0.69      0.37      0.48      4475\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.76      0.66      0.69     20000\n",
      "weighted avg       0.81      0.82      0.80     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the training data\n",
    "print(classification_report(y_train, d_dtc.predict(X_train), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Incredible       0.85      0.95      0.90      3927\n",
      "    Credible       0.67      0.38      0.48      1073\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.76      0.66      0.69      5000\n",
      "weighted avg       0.81      0.83      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the performance in the validation data\n",
    "print(classification_report(y_valid, d_dtc.predict(X_valid), target_names=['Incredible', 'Credible']))\n",
    "# Store the report to dataframe\n",
    "report = classification_report(y_valid, d_dtc.predict(X_valid), target_names=['Incredible', 'Credible'], output_dict=True)\n",
    "df_report_d_dtc = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After tests, 5 seems to be the best max_depth of the decision tree here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we use SVM instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rockwell/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build SVM model\n",
    "lm_svm = svm.SVC()\n",
    "# one-hot encoding for X2 (gender), X3(education), X4(martial status)\n",
    "train_onehot = train.copy()\n",
    "train_onehot = pd.get_dummies(train_onehot, columns=['X2', 'X3', 'X4'], prefix=['X2', 'X3', 'X4'])\n",
    "# remove the id column\n",
    "train_onehot.drop(labels='id', axis=1, inplace=True)\n",
    "# move label column to the last\n",
    "feature_cols = [col for col in train_onehot.columns if col != 'Y']\n",
    "train_onehot = train_onehot[feature_cols + ['Y']]\n",
    "# split data to train and validation\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(train_onehot.iloc[:,:-1], train_onehot['Y'], test_size=0.2)\n",
    "lm_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the performance in the training data\n",
    "print(classification_report(y_train, lm_svm.predict(X_train), target_names=['Incredible', 'Credible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the performance in the validation data\n",
    "print(classification_report(y_valid, lm_svm.predict(X_valid), target_names=['Incredible', 'Credible']))\n",
    "# Store the report to dataframe\n",
    "report = classification_report(y_valid, lm_svm.predict(X_valid), target_names=['Incredible', 'Credible'], output_dict=True)\n",
    "df_report_lm_svm = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(lm_svm.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of df_report for different classifier\n",
    "df_report_d_dtc = df_report_d_dtc.add_prefix('dtc_')\n",
    "df_report_lm_lr = df_report_lm_lr.add_prefix('lr_')\n",
    "df_report_lm_lr_no_onehot = df_report_lm_lr_no_onehot.add_prefix('lr_no_onehot_')\n",
    "df_report_lm_svm = df_report_lm_svm.add_prefix('svm_')\n",
    "\n",
    "df_report_all = df_report_lm_svm.merge(df_report_lm_lr_no_onehot.merge(df_report_lm_lr.merge(df_report_d_dtc, left_index=True, right_index=True),left_index=True, right_index=True),left_index=True, right_index=True)\n",
    "df_report_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fraud detection performance, i.e., recall for incredible and credible users\n",
    "df_report_all.plot(y=['svm_recall', 'lr_no_onehot_recall', 'lr_recall', 'dtc_recall'], kind='bar', figsize=(12,6), cmap='Spectral')\n",
    "plt.title('Recall for incredible and credible users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fraud detection performance, i.e., precision for incredible and credible users\n",
    "df_report_all.plot(y=['svm_precision', 'lr_no_onehot_precision', 'lr_precision', 'dtc_precision'], kind='bar', figsize=(12,6), cmap='Spectral')\n",
    "plt.title('Precision for incredible and credible users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fraud detection performance, i.e., F1-score for incredible and credible users\n",
    "df_report_all.plot(y=['svm_f1-score', 'lr_no_onehot_f1-score', 'lr_f1-score', 'dtc_f1-score'], kind='bar', figsize=(12,6), cmap='Spectral')\n",
    "plt.title('F1-score for incredible and credible users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, considering both recall, precision, and F-1 scores for credible and incredible users, we finally choose the decision tree classifier in this fraud detection case.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
